{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Novelty Check\n",
    "Testing the novelty analysis on a NACCER proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad1926q/nexml-rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "2025-11-28 19:40:15,136 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from scripts.doc_extractor import extract_text_images_tables\n",
    "from app.llm import check_novelty\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:40:15,936 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:40:16,058 - INFO - Going to convert document batch...\n",
      "2025-11-28 19:40:16,059 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 2c28ec89b014192881c35ecb45b96fd8\n",
      "2025-11-28 19:40:16,071 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-28 19:40:16,075 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-28 19:40:16,090 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-28 19:40:16,100 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-11-28 19:40:17,043 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,094 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,137 [RapidOCR] download_file.py:60: File exists and is valid: /home/saad1926q/nexml-rag/.venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,140 [RapidOCR] main.py:53: Using /home/saad1926q/nexml-rag/.venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,282 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,305 [RapidOCR] download_file.py:60: File exists and is valid: /home/saad1926q/nexml-rag/.venv/lib/python3.10/site-packages/rapidocr/models/ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,306 [RapidOCR] main.py:53: Using /home/saad1926q/nexml-rag/.venv/lib/python3.10/site-packages/rapidocr/models/ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,353 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,421 [RapidOCR] download_file.py:60: File exists and is valid: /home/saad1926q/nexml-rag/.venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-28 19:40:17,422 [RapidOCR] main.py:53: Using /home/saad1926q/nexml-rag/.venv/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-11-28 19:40:17,580 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-11-28 19:40:17,609 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-11-28 19:40:21,155 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-11-28 19:40:22,554 - INFO - Processing document NACCER_2024_RD_8535.pdf\n",
      "2025-11-28 19:40:28,036 - INFO - Finished converting document NACCER_2024_RD_8535.pdf in 10.55 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted proposal text (1229 characters)\n",
      "\n",
      "First 500 characters:\n",
      "## Research Proposal: NACCER/2024/RD/8535\n",
      "\n",
      "## Optimization of Flotation Process for Waste Minimization\n",
      "\n",
      "| Principal Investigator:   | Dr. Lakshmi Mehta   |\n",
      "|---------------------------|---------------------|\n",
      "| Institution:              | IISc Bangalore      |\n",
      "| Research Area:            | Mine Planning       |\n",
      "| Funding Source:           | CIL                 |\n",
      "| Duration:                 | 18 months           |\n",
      "| Submission Date:          | 2024-01-21          |\n",
      "\n",
      "## Abstract\n",
      "\n",
      "The proposed study\n"
     ]
    }
   ],
   "source": [
    "# Extract text from PDF\n",
    "file_path = '../documents/NACCER_2024_RD_8535.pdf'\n",
    "doc_list = extract_text_images_tables(file_path)\n",
    "\n",
    "# Get the proposal text\n",
    "proposal_text = doc_list[0].page_content\n",
    "\n",
    "print(f\"Extracted proposal text ({len(proposal_text)} characters)\")\n",
    "print(\"\\nFirst 500 characters:\")\n",
    "print(proposal_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:40:28,106 - INFO - Use pytorch device_name: cuda:0\n",
      "2025-11-28 19:40:28,107 - INFO - Load pretrained SentenceTransformer: sentence-transformers/clip-ViT-B-32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running novelty analysis...\n",
      "\n",
      "Embedding type: <class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 19:40:34,233 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NOVELTY ANALYSIS RESULT\n",
      "================================================================================\n",
      "**Novelty Analysis Report: NACCER/2024/RD/8535**\n",
      "\n",
      "**Introduction:**\n",
      "\n",
      "The primary objective of this novelty analysis is to assess the originality and uniqueness of the research proposal \"Optimization of Flotation Process for Waste Minimization\" (NACCER/2024/RD/8535) in comparison with similar past proposals submitted to NACCER.\n",
      "\n",
      "**1. Key Similarities with Past Proposals:**\n",
      "\n",
      "After reviewing the similar past proposals submitted to NACCER, it appears that several proposals have focused on mine planning and optimization of mineral processing techniques. The following key similarities were identified:\n",
      "\n",
      "* Proposal NACCER/2019/RD/4211: \"Optimization of Flotation Process for Improved Mineral Recovery\" (Principal Investigator: Dr. Ramakrishnan)\n",
      "* Proposal NACCER/2017/RD/2345: \"Development of Advanced Flotation Techniques for Sustainable Mining Practices\" (Principal Investigator: Dr. Kumar)\n",
      "\n",
      "These proposals share similarities with the current proposal in terms of their focus on flotation process optimization and mine planning. However, the current proposal appears to build upon the existing knowledge in this area by incorporating modern AI techniques.\n",
      "\n",
      "**2. Novel Aspects of the Current Proposal:**\n",
      "\n",
      "The current proposal introduces several novel aspects that differentiate it from the similar past proposals:\n",
      "\n",
      "* **Combination of Traditional Methods with AI Techniques:** The proposal aims to develop a novel methodology by combining traditional methods with modern AI techniques for comprehensive analysis and implementation. This approach is not explicitly mentioned in the similar past proposals.\n",
      "* **Focus on Waste Minimization:** While the similar past proposals focused on mineral recovery and sustainable mining practices, the current proposal specifically targets waste minimization, which is a critical aspect of sustainable mining practices.\n",
      "* **Innovative Use of AI in Flotation Process Optimization:** The proposal's emphasis on AI-driven optimization of the flotation process is a novel aspect that sets it apart from the similar past proposals.\n",
      "\n",
      "**3. Overall Novelty Assessment:**\n",
      "\n",
      "Based on the analysis of the key similarities and novel aspects, I would assess the overall novelty of the current proposal as **Medium**. The proposal builds upon existing knowledge in the area of mine planning and flotation process optimization but introduces novel aspects, such as the combination of traditional methods with AI techniques and the focus on waste minimization. However, the proposal does not break new ground in terms of fundamental research or completely new ideas, which is why I do not classify it as highly novel.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "Based on this novelty analysis, I recommend that the current proposal be evaluated further to assess its potential for innovative and impactful research in the field of mine planning and flotation process optimization. The proposal's novel aspects, such as the combination of traditional methods with AI techniques and the focus on waste minimization, make it a promising candidate for funding.\n"
     ]
    }
   ],
   "source": [
    "# Run novelty check\n",
    "print(\"Running novelty analysis...\\n\")\n",
    "novelty_result = await check_novelty(proposal_text)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NOVELTY ANALYSIS RESULT\")\n",
    "print(\"=\"*80)\n",
    "print(novelty_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*, name: str = 'semanticscholar', description: str = 'A wrapper around semantischolar.org Useful for when you need to answer to questionsfrom research papers.Input should be a search query.', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain_community.tools.semanticscholar.tool.SemantscholarInput'>, return_direct: bool = False, verbose: bool = False, callbacks: list[langchain_core.callbacks.base.BaseCallbackHandler] | langchain_core.callbacks.base.BaseCallbackManager | None = None, tags: list[str] | None = None, metadata: dict[str, typing.Any] | None = None, handle_tool_error: bool | str | collections.abc.Callable[[langchain_core.tools.base.ToolException], str] | None = False, handle_validation_error: bool | str | collections.abc.Callable[[pydantic_core._pydantic_core.ValidationError | pydantic.v1.error_wrappers.ValidationError], str] | None = False, response_format: Literal['content', 'content_and_artifact'] = 'content', api_wrapper: langchain_community.utilities.semanticscholar.SemanticScholarAPIWrapper = <factory>) -> None\n",
      "Help on function run in module langchain_core.tools.base:\n",
      "\n",
      "run(self, tool_input: 'str | dict[str, Any]', verbose: 'bool | None' = None, start_color: 'str | None' = 'green', color: 'str | None' = 'green', callbacks: 'Callbacks' = None, *, tags: 'list[str] | None' = None, metadata: 'dict[str, Any] | None' = None, run_name: 'str | None' = None, run_id: 'uuid.UUID | None' = None, config: 'RunnableConfig | None' = None, tool_call_id: 'str | None' = None, **kwargs: 'Any') -> 'Any'\n",
      "    Run the tool.\n",
      "    \n",
      "    Args:\n",
      "        tool_input: The input to the tool.\n",
      "        verbose: Whether to log the tool's progress.\n",
      "        start_color: The color to use when starting the tool.\n",
      "        color: The color to use when ending the tool.\n",
      "        callbacks: Callbacks to be called during tool execution.\n",
      "        tags: Optional list of tags associated with the tool.\n",
      "        metadata: Optional metadata associated with the tool.\n",
      "        run_name: The name of the run.\n",
      "        run_id: The id of the run.\n",
      "        config: The configuration for the tool.\n",
      "        tool_call_id: The id of the tool call.\n",
      "        **kwargs: Keyword arguments to be passed to tool callbacks (event handler)\n",
      "    \n",
      "    Returns:\n",
      "        The output of the tool.\n",
      "    \n",
      "    Raises:\n",
      "        ToolException: If an error occurs during tool execution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from langchain_community.tools.semanticscholar.tool import SemanticScholarQueryRun\n",
    "print(inspect.signature(SemanticScholarQueryRun))\n",
    "help(SemanticScholarQueryRun.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexml-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
